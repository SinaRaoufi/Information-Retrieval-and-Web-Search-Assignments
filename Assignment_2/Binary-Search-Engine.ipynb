{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Build a simple binary search engine\n",
    "\n",
    "1- Create Dictionary/Vocabulary.    \n",
    "2- For each term in the dictionary, create a posting list for it    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "[**RCV1 (Reuters Corpus Volume 1)**](https://www.jmlr.org/papers/volume5/lewis04a/lewis04a.pdf) is a widely used dataset in machine learning and natural language processing (NLP) research. It is a **collection of newswire stories** collected from the Reuters news agency in 1996. The RCV1 dataset contains approximately 800,000 manually categorized newswire stories from over 100 categories, such as politics, business, sports, and entertainment.   \n",
    "For simplicity, we just use train subset of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parse the text and extract the ID and terms for each document\n",
    "with open('lyrl2004_vectors_train.dat', 'rb') as f:\n",
    "    text = f.read().decode('utf-8')\n",
    "documents = []\n",
    "\n",
    "for doc in text.split('.I ')[1:]:\n",
    "    doc_id, doc_text = doc.split('\\n.W\\n')\n",
    "    terms = doc_text.split()\n",
    "    documents.append({'ID': doc_id, 'Terms': ' '.join(terms)})\n",
    "\n",
    "# Create a DataFrame with the ID and terms for each document\n",
    "df = pd.DataFrame(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2286</td>\n",
       "      <td>recov recov recov recov excit excit bring mexi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2287</td>\n",
       "      <td>uruguay uruguay compan compan compan bring lim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2288</td>\n",
       "      <td>spun stak compan compan compan compan compan c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2289</td>\n",
       "      <td>spun stak compan compan compan compan compan c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2290</td>\n",
       "      <td>compan compan limit planet planet planet plane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23144</th>\n",
       "      <td>26145</td>\n",
       "      <td>ipi ipi ipi ipi ipi study market tight protest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23145</th>\n",
       "      <td>26146</td>\n",
       "      <td>compan market launch ag target target saturday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23146</th>\n",
       "      <td>26147</td>\n",
       "      <td>allot guent capac market saxon saxon saxon sax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23147</th>\n",
       "      <td>26148</td>\n",
       "      <td>limit draw protest protest gener specif illeg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23148</th>\n",
       "      <td>26150</td>\n",
       "      <td>der saxon saxon saxon saxon saxon struck struc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23149 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                              Terms\n",
       "0       2286  recov recov recov recov excit excit bring mexi...\n",
       "1       2287  uruguay uruguay compan compan compan bring lim...\n",
       "2       2288  spun stak compan compan compan compan compan c...\n",
       "3       2289  spun stak compan compan compan compan compan c...\n",
       "4       2290  compan compan limit planet planet planet plane...\n",
       "...      ...                                                ...\n",
       "23144  26145  ipi ipi ipi ipi ipi study market tight protest...\n",
       "23145  26146  compan market launch ag target target saturday...\n",
       "23146  26147  allot guent capac market saxon saxon saxon sax...\n",
       "23147  26148  limit draw protest protest gener specif illeg ...\n",
       "23148  26150  der saxon saxon saxon saxon saxon struck struc...\n",
       "\n",
       "[23149 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document-Term matrix\n",
    "A *document-term matrix* is a **mathematical representation of text data**, where **rows represent individual terms**(words, phrases, or concepts) and **columns represent documents**. Each cell in the matrix contains the frequency or occurrence of a specific term in a particular document. The matrix can be binary, where each cell contains a 1 if the term is present in the document and a 0 if it is not, or it can be weighted, where the cell value is the frequency of the term in the document. The document-term matrix is a crucial component in many Natural Language Processing (NLP) and text mining tasks, such as topic modeling, sentiment analysis, and information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Build the document-term matrix using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['Terms'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posting List\n",
    "In computer science, a *posting list* is a database index storing a mapping from content, such as words or numbers, to its locations in a table, or in a document or a set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a posting list for each term\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "posting_lists = {}\n",
    "for i, term in enumerate(terms):\n",
    "    doc_indices = X[:, i].nonzero()[0]\n",
    "    real_ids = [df.iloc[x].ID for x in doc_indices.tolist()]\n",
    "    posting_lists[term] = real_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the unique terms to a file\n",
    "with open('unique_terms.txt', 'w') as f:\n",
    "    f.write('\\n'.join(terms))\n",
    "    \n",
    "# Save the posting lists to a file\n",
    "with open('posting_lists.txt', 'w') as f:\n",
    "    for term, posting_list in posting_lists.items():\n",
    "        posting_str = ' '.join(str(doc_id) for doc_id in posting_list)\n",
    "        f.write(f'{term}: {posting_str}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Search\n",
    "[Binary search](https://www.programiz.com/dsa/binary-search) is a **searching algorithm** for **finding an element’s position in a sorted list**. In this approach, the element is always searched in the middle of a portion of a list. Binary search can be implemented only on a sorted list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(search_term):\n",
    "    # Open the posting_lists.txt file in read mode and read all the lines into a list\n",
    "    with open('posting_lists.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Initialize the indices for binary search\n",
    "    left = 0\n",
    "    right = len(lines) - 1\n",
    "    \n",
    "    # Loop until left index crosses the right index\n",
    "    while left <= right:\n",
    "        # Find the middle index of the current search range\n",
    "        mid = (left + right) // 2\n",
    "        # Extract the line corresponding to the middle index\n",
    "        line = lines[mid]\n",
    "        # Split the line into term and document IDs string using the colon separator\n",
    "        term, document_ids = line.strip().split(': ')\n",
    "        \n",
    "        # Compare the search term with the current term\n",
    "        if term == search_term:\n",
    "            # If the search term matches the current term, return the list of document IDs as a list of strings\n",
    "            return document_ids.split()\n",
    "        elif term < search_term:\n",
    "            # If the current term is smaller than the search term, update the left index to search in the right half\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            # If the current term is greater than the search term, update the right index to search in the left half\n",
    "            right = mid - 1\n",
    "            \n",
    "    # If the search term is not found, return None\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search():\n",
    "    term = str(input('Search term...'))\n",
    "    document_ids = binary_search(term)\n",
    "\n",
    "    print(f'Searched term: {term}')\n",
    "    # Check if the search term was found or not, and print the corresponding result\n",
    "    if document_ids is not None:\n",
    "        print(f'Document IDs: {document_ids}')\n",
    "    else:\n",
    "        print('Sorry, the given term not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searched term: forehead\n",
      "Document IDs: ['14072', '16696', '16849', '24284', '24292']\n"
     ]
    }
   ],
   "source": [
    "# forehead\n",
    "search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searched term: girlfriend\n",
      "Document IDs: ['4163', '6240', '7592', '12105', '16679', '16888', '17988', '18099', '18209', '19765', '20383', '21133', '22477', '24514', '25253']\n"
     ]
    }
   ],
   "source": [
    "# girlfriend\n",
    "search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searched term: apple\n",
      "Sorry, the given term not found!\n"
     ]
    }
   ],
   "source": [
    "# apple\n",
    "search()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
